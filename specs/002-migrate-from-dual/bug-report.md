# Bug Report: Phase 4 Implementation Issues
**Date**: 2025-10-15
**Reporter**: Claude Code
**Severity**: Critical - Feature Non-Functional
**Component**: IBKR Integration, DataCatalogService

---

## Overview

Phase 4 (User Story 2 - Automatic Data Fetching) was marked complete in `tasks.md` but was actually **never implemented**. The `DataCatalogService.fetch_or_load()` method exists but the IBKR client it depends on was never initialized or connected. Testing revealed 8 distinct bugs, 7 of which have been fixed.

---

## Bug #1: IBKR Client Not Initialized ‚úÖ FIXED

### Details
- **Severity**: Critical
- **File**: `src/services/data_catalog.py`
- **Line**: `__init__()` method (line ~42)
- **Discovered**: First test attempt

### Description
The `DataCatalogService.__init__()` never initialized `self.ibkr_client`, but `_is_ibkr_available()` checked for its existence with `hasattr(self, "ibkr_client")`. This always returned `False`, causing all auto-fetch attempts to fail immediately.

### Error Message
```python
2025-10-15 14:27:21 [debug] ibkr_client_not_initialized
```

### Root Cause
The implementation assumed `ibkr_client` would be passed in or initialized elsewhere, but no calling code did this.

### Fix Applied
```python
def __init__(
    self,
    catalog_path: str | Path | None = None,
    ibkr_client: IBKRHistoricalClient | None = None,
) -> None:
    # ... existing code ...

    # Reason: Initialize IBKR client for auto-fetch functionality
    if ibkr_client is not None:
        self.ibkr_client = ibkr_client
    else:
        # Reason: Create default IBKR client with env settings
        ibkr_host = os.environ.get("IBKR_HOST", "127.0.0.1").split("#")[0].strip()
        ibkr_port_str = os.environ.get("IBKR_PORT", "7497").split("#")[0].strip()
        ibkr_client_id_str = os.environ.get("IBKR_CLIENT_ID", "10").split("#")[0].strip()

        ibkr_port = int(ibkr_port_str)
        ibkr_client_id = int(ibkr_client_id_str)

        self.ibkr_client = IBKRHistoricalClient(
            host=ibkr_host,
            port=ibkr_port,
            client_id=ibkr_client_id,
        )
```

### Impact
- **Before**: Auto-fetch never attempted
- **After**: IBKR client properly initialized and connection attempted

---

## Bug #2: Missing `await` Keyword ‚úÖ FIXED

### Details
- **Severity**: Critical
- **File**: `src/services/data_catalog.py`
- **Line**: 576
- **Discovered**: Second test attempt

### Description
Method `_is_ibkr_available()` was changed from sync to async but the call site at line 576 was not updated to use `await`. This caused a RuntimeWarning and the coroutine was never actually executed.

### Error Message
```
RuntimeWarning: coroutine 'DataCatalogService._is_ibkr_available' was never awaited
  if not self._is_ibkr_available():
```

### Root Cause
Incomplete refactoring when converting `_is_ibkr_available()` to async.

### Fix Applied
```python
# Before:
if not self._is_ibkr_available():

# After:
if not await self._is_ibkr_available():
```

### Impact
- **Before**: Connection check never executed, always returned False
- **After**: Connection check properly awaited and executed

---

## Bug #3: Missing `fetch_bars()` Method ‚úÖ FIXED

### Details
- **Severity**: Critical
- **File**: `src/services/ibkr_client.py`
- **Line**: N/A (method didn't exist)
- **Discovered**: Third test attempt

### Description
`DataCatalogService._fetch_from_ibkr_with_retry()` called `self.ibkr_client.fetch_bars()` but `IBKRHistoricalClient` had no such method. Only `connect()`, `disconnect()`, and `is_connected` property existed.

### Error Message
```
'IBKRHistoricalClient' object has no attribute 'fetch_bars'
```

### Root Cause
The wrapper class `IBKRHistoricalClient` was created but the actual data fetching method was never implemented.

### Fix Applied
Implemented complete `fetch_bars()` method in `IBKRHistoricalClient`:
```python
async def fetch_bars(
    self,
    instrument_id: str,
    start: datetime,
    end: datetime,
    bar_type_spec: str = "1-MINUTE-LAST",
):
    """Fetch historical bars from IBKR."""
    await self.rate_limiter.acquire()

    # Parse instrument_id and bar_type_spec
    parts = instrument_id.split(".")
    symbol, venue = parts

    # Create bar specification
    bar_spec = f"{symbol}.{venue}-{bar_type_spec}-EXTERNAL"

    # Strip timezone info for Nautilus
    start_naive = start.replace(tzinfo=None) if start.tzinfo else start
    end_naive = end.replace(tzinfo=None) if end.tzinfo else end

    # Request bars from Nautilus client
    bars = await self.client.request_bars(
        bar_specifications=[bar_spec],
        start_date_time=start_naive,
        end_date_time=end_naive,
        tz_name="UTC",
        instrument_ids=[instrument_id],
    )

    return bars
```

### Impact
- **Before**: AttributeError, no data fetch possible
- **After**: Method exists and attempts to fetch data

---

## Bug #4: Environment Variable Parsing ‚úÖ FIXED

### Details
- **Severity**: Medium
- **File**: `src/services/data_catalog.py`
- **Line**: ~79-81 (in `__init__`)
- **Discovered**: During port mismatch investigation

### Description
Two issues with environment variable handling:
1. Inline comments in `.env` file (e.g., `IBKR_PORT=7497 # comment`) were not handled
2. System environment variables were overriding `.env` values (python-dotenv default behavior)

### Observed Behavior
```bash
# .env file had:
IBKR_PORT=7497       # 7497=TWS paper, 7496=TWS live...

# But Python read:
IBKR_PORT=4002  # From system environment variable
```

### Root Cause
1. `os.environ.get()` doesn't strip inline comments
2. python-dotenv by default doesn't override existing env vars

### Fix Applied
```python
# Strip whitespace and handle inline comments
ibkr_host = os.environ.get("IBKR_HOST", "127.0.0.1").split("#")[0].strip()
ibkr_port_str = os.environ.get("IBKR_PORT", "7497").split("#")[0].strip()
ibkr_client_id_str = os.environ.get("IBKR_CLIENT_ID", "10").split("#")[0].strip()
```

### Impact
- **Before**: Connected to wrong port (4002 instead of 7497)
- **After**: Correctly reads port from environment

### Additional Note
User's shell had `IBKR_PORT=4002` set system-wide, which was overriding the `.env` file. This is environment-specific and not a code bug.

---

## Bug #5: Incorrect `request_bars()` Parameters ‚úÖ FIXED

### Details
- **Severity**: Critical
- **File**: `src/services/ibkr_client.py`
- **Line**: 184-188 (in `fetch_bars()`)
- **Discovered**: Fourth test attempt

### Description
Called Nautilus `request_bars()` with wrong parameter names. Used `bar_type`, `start`, `end` instead of correct names `bar_specifications`, `start_date_time`, `end_date_time`.

### Error Message
```
HistoricInteractiveBrokersClient.request_bars() got an unexpected keyword argument 'bar_type'
```

### Root Cause
Didn't check Nautilus API documentation for correct parameter names.

### Fix Applied
```python
# Before:
bars = await self.client.request_bars(
    bar_type=bar_spec,
    start=start,
    end=end,
)

# After:
bars = await self.client.request_bars(
    bar_specifications=[bar_spec],  # List of strings
    start_date_time=start_naive,     # Correct parameter name
    end_date_time=end_naive,         # Correct parameter name
    tz_name="UTC",
)
```

### Impact
- **Before**: TypeError on every call
- **After**: Correct parameters passed to Nautilus

---

## Bug #6: Timezone Handling ‚úÖ FIXED

### Details
- **Severity**: Medium
- **File**: `src/services/ibkr_client.py`
- **Line**: 189-191 (in `fetch_bars()`)
- **Discovered**: Fifth test attempt

### Description
Passed timezone-aware datetime objects along with `tz_name` parameter. Pandas/Nautilus rejects this combination with an error.

### Error Message
```
Cannot pass a datetime or Timestamp with tzinfo with the tz parameter.
Use tz_convert instead.
```

### Root Cause
Datetime objects from the backtest command have `tzinfo=UTC` set, but Nautilus `request_bars()` expects naive datetimes when `tz_name` is provided.

### Fix Applied
```python
# Strip timezone info since we're specifying tz_name parameter
start_naive = start.replace(tzinfo=None) if start.tzinfo else start
end_naive = end.replace(tzinfo=None) if end.tzinfo else end

bars = await self.client.request_bars(
    bar_specifications=[bar_spec],
    start_date_time=start_naive,  # Now naive
    end_date_time=end_naive,      # Now naive
    tz_name="UTC",                # Explicit timezone
    instrument_ids=[instrument_id],
)
```

### Impact
- **Before**: ValueError on every request
- **After**: Datetimes properly formatted for Nautilus

---

## Bug #7: Missing `instrument_ids` Parameter ‚úÖ FIXED

### Details
- **Severity**: Medium
- **File**: `src/services/ibkr_client.py`
- **Line**: 189 (in `fetch_bars()`)
- **Discovered**: Sixth test attempt

### Description
Nautilus `request_bars()` requires either `contracts` or `instrument_ids` parameter to be provided. Neither was initially included.

### Error Message
```
Either contracts or instrument_ids must be provided
```

### Root Cause
Incomplete understanding of Nautilus API requirements.

### Fix Applied
```python
bars = await self.client.request_bars(
    bar_specifications=[bar_spec],
    start_date_time=start_naive,
    end_date_time=end_naive,
    tz_name="UTC",
    instrument_ids=[instrument_id],  # Added this line
)
```

### Impact
- **Before**: ValueError, no instrument specified
- **After**: Instrument properly specified for lookup

---

## Bug #8: Bar Specification Format ‚úÖ FIXED

### Details
- **Severity**: Critical (BLOCKER)
- **File**: `src/services/ibkr_client.py`
- **Line**: 181 (bar_spec construction)
- **Discovered**: Seventh test attempt
- **Fixed**: 2025-10-15 15:02 PST
- **Status**: FIXED

### Description
The bar specification string format didn't match what Nautilus IBKR adapter expects. Was creating format `AAPL.NASDAQ-1-MINUTE-LAST-EXTERNAL` but Nautilus expected simple format strings.

### Error Message
```
invalid literal for int() with base 10: 'AAPL.NASDAQ-1-MINUTE'
```

### Root Cause
**Incorrect understanding of Nautilus API**. The `bar_specifications` parameter expects simple format strings (e.g., `"1-MINUTE-LAST"`), while instrument identification should come from the separate `contracts` parameter using `IBContract` objects.

### Research Process
1. Used Context7 MCP tool to fetch Nautilus Trader documentation
2. Found official example showing correct format:
   ```python
   bars = await client.request_bars(
       bar_specifications=["1-MINUTE-LAST"],  # Simple format!
       contracts=contracts,  # Instrument ID here!
       ...
   )
   ```
3. Realized the mistake in our implementation

### Fix Applied

**Change 1: Add IBContract Import**
```python
from nautilus_trader.adapters.interactive_brokers.common import IBContract
```

**Change 2: Fix fetch_bars() Method**
```python
# Before:
bar_spec = f"{symbol}.{venue}-{bar_type_spec}-EXTERNAL"
bars = await self.client.request_bars(
    bar_specifications=[bar_spec],
    instrument_ids=[instrument_id],  # Wrong parameter!
)

# After:
contract = IBContract(
    secType="STK",
    symbol=symbol,
    exchange="SMART",
    primaryExchange=venue,
    currency="USD",
)
bars = await self.client.request_bars(
    bar_specifications=[bar_type_spec],  # Just "1-MINUTE-LAST"!
    contracts=[contract],  # Correct parameter!
    use_rth=True,
    timeout=120,
)
```

### Test Result
```
‚úÖ Fetched 60 bars from IBKR in 2.31s
   üíæ Data saved to catalog - future backtests will use cached data

$ ls -lh data/catalog/data/bar/AAPL.NASDAQ-1-MINUTE-LAST-EXTERNAL/
-rw-r--r--  1 allay  staff   5.2K Oct 15 15:01 2023-12-29T20-01-00-000000000Z_2023-12-29T21-00-00-000000000Z.parquet
```

### Impact
- **Before**: Data fetch completely blocked
- **After**: Data fetch working, 60 bars fetched successfully
- **Enables**: User Story 2 completion and User Story 1 testing

---

## Bug #9: Instrument Not Added to Backtest Cache ‚è≥ NEEDS FIX

### Details
- **Severity**: Critical (BLOCKER)
- **File**: `src/core/backtest_runner.py`
- **Line**: Unknown (needs investigation)
- **Discovered**: After Bug #8 fix, during backtest execution
- **Status**: NOT FIXED

### Description
After successfully fetching data from IBKR, the backtest engine fails because it cannot find the `AAPL.NASDAQ` instrument definition in its cache. The instrument was fetched from IBKR (as evidenced by successful contract qualification), but was never added to the backtest engine's cache.

### Error Message
```
‚ùå Backtest failed: `Instrument` AAPL.NASDAQ for the given data not found in the
cache. Add the instrument through `add_instrument()` prior to adding related
data.
```

### Observed Behavior
```
[INFO] TRADER-000.InteractiveBrokersInstrumentProvider: ...
[INFO] Contract qualified for AAPL.NASDAQ with ConId=265598
...
[INFO] TRADER-000.SimulatedExchange(SIM): Added instrument AAPL.SIM and created matching engine
‚ùå Backtest failed: `Instrument` AAPL.NASDAQ for the given data not found
```

The backtest engine creates `AAPL.SIM` instrument but expects `AAPL.NASDAQ` for the data.

### Root Cause
The instrument definition fetched from IBKR needs to be explicitly passed to the backtest engine before adding the bar data. The backtest runner is likely missing:
1. Retrieval of instrument from IBKR instrument provider
2. Call to `engine.add_instrument(instrument)` before `engine.add_data(bars)`

### Impact
- **Current**: Backtest execution completely blocked
- **Blocks**: User Story 2 completion, User Story 1 testing
- **Severity**: Data fetch works but cannot be used

### Investigation Needed
1. Check `src/core/backtest_runner.py` for instrument handling
2. Verify instrument is being returned from `fetch_or_load()`
3. Ensure instrument is added to engine before data

---

## Bug #10: Availability Cache Not Detecting Parquet Files ‚è≥ NEEDS FIX

### Details
- **Severity**: High (Performance Issue)
- **File**: `src/services/data_catalog.py`
- **Line**: Availability cache rebuild logic
- **Discovered**: Second test run showed cache miss despite existing data
- **Status**: NOT FIXED

### Description
Even though Parquet files exist in the catalog directory, the availability cache rebuild shows 0 entries. This causes the system to fetch from IBKR again on every run instead of using cached data, defeating the purpose of caching.

### Error Symptoms
```
2025-10-15 15:01:49 [info] rebuilding_availability_cache
2025-10-15 15:01:49 [info] availability_cache_rebuilt total_entries=0
2025-10-15 15:01:49 [debug] availability_cache_miss bar_type_spec=1-MINUTE-LAST instrument_id=AAPL.NASDAQ
```

### Observed Behavior
```bash
# First run:
‚úÖ Fetched 60 bars from IBKR in 2.31s
   üíæ Data saved to catalog

# File exists:
$ ls data/catalog/data/bar/AAPL.NASDAQ-1-MINUTE-LAST-EXTERNAL/
2023-12-29T20-01-00-000000000Z_2023-12-29T21-00-00-000000000Z.parquet

# Second run:
2025-10-15 15:01:49 [info] availability_cache_rebuilt total_entries=0
‚ö†Ô∏è  No data in catalog for AAPL
   Will attempt to fetch from IBKR...
‚úÖ Fetched 60 bars from IBKR in 2.18s  # Should have loaded from cache!
```

### Root Cause Possibilities
1. **Path mismatch**: Catalog is scanning wrong directory
2. **Pattern mismatch**: File naming doesn't match expected pattern
3. **Date format**: Filename timestamp format not being parsed correctly
4. **Query logic**: Availability cache query doesn't match file structure
5. **Catalog initialization**: ParquetDataCatalog not being initialized with correct path

### Impact
- **Current**: Cache never used, always fetches from IBKR
- **Performance**: Extra 2-3 seconds per backtest
- **API Usage**: Unnecessary IBKR API calls (rate limit risk)
- **User Story 1**: Cannot test cached data loading

### Investigation Needed
1. Check availability cache rebuild logic in `data_catalog.py`
2. Verify catalog path is correct
3. Test ParquetDataCatalog.list_data_files() manually
4. Check if date range query matches file naming convention
5. Verify catalog is being passed to backtest engine correctly

---

## Summary Table

| Bug # | Description | Severity | Status | File |
|-------|-------------|----------|--------|------|
| 1 | IBKR client not initialized | Critical | ‚úÖ Fixed | data_catalog.py |
| 2 | Missing await keyword | Critical | ‚úÖ Fixed | data_catalog.py |
| 3 | Missing fetch_bars() method | Critical | ‚úÖ Fixed | ibkr_client.py |
| 4 | Env var parsing issues | Medium | ‚úÖ Fixed | data_catalog.py |
| 5 | Wrong request_bars() params | Critical | ‚úÖ Fixed | ibkr_client.py |
| 6 | Timezone handling | Medium | ‚úÖ Fixed | ibkr_client.py |
| 7 | Missing instrument_ids param | Medium | ‚úÖ Fixed | ibkr_client.py |
| 8 | Bar specification format | Critical | ‚úÖ Fixed | ibkr_client.py |
| 9 | Instrument not added to cache | Critical | ‚è≥ Needs Fix | backtest_runner.py |
| 10 | Availability cache not working | High | ‚è≥ Needs Fix | data_catalog.py |

**Fixed**: 8/10 (80%)
**Remaining**: 2 blockers (1 critical, 1 high)

---

## Impact Assessment

### Before Fixes (Initial State)
- ‚ùå IBKR integration completely non-functional
- ‚ùå Auto-fetch feature did not work at all
- ‚ùå No data could be fetched from IBKR
- ‚ùå Phase 4 falsely marked as complete

### After First 7 Fixes (Session 1)
- ‚úÖ IBKR connection successful
- ‚úÖ Instrument lookup working
- ‚úÖ Retry logic functioning
- ‚úÖ Error messages clear and actionable
- ‚è≥ Data fetch blocked on format issue (Bug #8)

### After Bug #8 Fix (Session 2)
- ‚úÖ IBKR connection successful
- ‚úÖ Instrument lookup working
- ‚úÖ Retry logic functioning
- ‚úÖ Error messages clear and actionable
- ‚úÖ Data fetch working (60 bars in 2.3s)
- ‚úÖ Parquet files created successfully (5.2KB)
- ‚è≥ Backtest execution blocked (Bug #9)
- ‚è≥ Cache not working (Bug #10)

### What Works Now
1. Environment configuration from .env
2. IBKR client initialization
3. TWS connection (tested with v187)
4. Instrument contract lookup (AAPL.NASDAQ ‚Üí ConId=265598)
5. Rate limiting with sliding window (45 req/sec)
6. Exponential backoff retry (2s, 4s, 8s)
7. Clear error messages
8. **Bar data fetch from IBKR** (60 bars in 2.3s) ‚ú® NEW
9. **Parquet file creation** (5.2KB files) ‚ú® NEW
10. **Correct bar specification format** ‚ú® NEW

### What Still Needs Work
1. ~~Bar specification format (Bug #8)~~ ‚úÖ FIXED
2. ~~End-to-end data fetch from IBKR~~ ‚úÖ FIXED
3. ~~Parquet file creation and persistence~~ ‚úÖ FIXED
4. **Instrument registration with backtest engine (Bug #9)** üî¥ NEW BLOCKER
5. **Availability cache detection (Bug #10)** üü° NEW ISSUE
6. **Backtest execution after data fetch** üî¥ BLOCKED BY #9
7. Integration tests for IBKR flow

---

## Prevention Recommendations

### Code Review Process
1. **Require Integration Tests**: Don't mark features complete without end-to-end tests
2. **Test Before Committing**: Run actual tests, not just unit tests
3. **Verify External Integrations**: Test with real IBKR connection, not just mocks

### Development Process
1. **Incremental Development**: Build and test each piece before marking complete
2. **Documentation**: Document assumptions about external APIs (Nautilus format requirements)
3. **Error Handling**: Add detailed logging early to catch issues faster

### Testing Standards
1. **Manual Testing Required**: Complex integrations need manual verification
2. **Environment Parity**: Test in environment similar to production (real IBKR connection)
3. **Regression Tests**: Create tests for each bug fix to prevent reoccurrence

---

## Next Steps

### Immediate
1. ~~Research Nautilus bar specification format (Bug #8)~~ ‚úÖ DONE
2. ~~Try alternative approaches (contracts vs bar_specifications)~~ ‚úÖ DONE
3. **Fix Bug #9**: Add instrument to backtest cache
   - Investigate `backtest_runner.py`
   - Retrieve instrument from IBKR provider
   - Call `engine.add_instrument()` before data
4. **Fix Bug #10**: Debug availability cache
   - Check catalog path and file scanning
   - Test ParquetDataCatalog manually
   - Verify date range queries

### Short Term
1. Complete User Story 2 testing (blocked by Bug #9)
2. Complete User Story 1 testing (blocked by Bug #10)
3. Create integration test suite for IBKR flow
4. Add mock IBKR responses for deterministic testing
5. ~~Document correct bar specification format~~ ‚úÖ DONE (BUG-8-FIX.md)
6. Update tasks.md to reflect actual status

### Long Term
1. Improve code review process
2. Add pre-commit hooks for integration tests
3. Create test data generation scripts
4. Document all Nautilus API quirks discovered
5. Add date validation for market holidays

---

## Lessons Learned

1. **External API Integration is Complex**: Nautilus Trader IBKR adapter has specific requirements that weren't obvious
2. **Testing is Essential**: Code that "looks right" may not work without actual testing
3. **Environment Variables Matter**: System env vars can silently override .env files
4. **Incremental Testing**: Test each component as it's built, not after everything is "done"
5. **Documentation is Key**: Document assumptions and requirements for external APIs
6. **Research Tools Are Invaluable**: Context7 MCP tool provided accurate Nautilus documentation with examples ‚ú® NEW
7. **Bug Cascades**: Fixing one bug often reveals the next blocker in the chain ‚ú® NEW
8. **Data Formats Matter**: API parameter formats and stored data formats can differ significantly ‚ú® NEW

---

## Conclusion

**Eight out of ten bugs have been fixed** across two testing sessions, significantly improving the IBKR integration. The system can now:
- ‚úÖ Connect to IBKR TWS successfully
- ‚úÖ Look up instruments and resolve contracts
- ‚úÖ Fetch historical bar data from IBKR (60 bars in 2.3s)
- ‚úÖ Create Parquet files in the catalog (5.2KB)
- ‚úÖ Handle errors gracefully with clear messages

**Progress**: From 0% ‚Üí 80% functional

### Remaining Blockers

**Bug #9 (Critical)**: Instrument not being added to backtest cache before data, preventing backtest execution
**Bug #10 (High)**: Availability cache not detecting Parquet files, causing unnecessary IBKR fetches

### Status by User Story

- **User Story 3 (Error Messages)**: ‚úÖ PASSING
- **User Story 2 (Auto-fetch)**: üü° 80% complete (data fetch works, backtest blocked)
- **User Story 1 (Cached Data)**: üî¥ BLOCKED (cache not working)

### Recommendation

Fix Bug #9 first (critical blocker for backtest execution), then Bug #10 (enables cache performance). Both bugs are now well-documented with clear investigation paths. The data fetching layer is working correctly - remaining issues are in integration with the backtest engine.
